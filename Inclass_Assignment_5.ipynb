{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Inclass_Assignment 5",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayaBhargavi198/5731Assignments/blob/master/Inclass_Assignment_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYp98zuTqXzU"
      },
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install selenium\n",
        "!pip install textblob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20rM_MZ-rx7W"
      },
      "source": [
        "# Webscrap and collect data using selenium\n",
        "from selenium import webdriver\n",
        "import time\n",
        "import pandas as pd\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "# open it, go to a website, and get results\n",
        "driver = webdriver.Chrome('chromedriver',options=options)\n",
        "driver.get(\"https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv\") \n",
        "for i in range(0,3):\n",
        "  button =driver.find_element_by_xpath('//*[@id = \"load-more-trigger\"]').click()\n",
        "  time.sleep(5)\n",
        "output = list()\n",
        "reviews = driver.find_elements_by_class_name(\"content\")\n",
        "for review in reviews:\n",
        "  output.append(review.find_element_by_css_selector(\".text.show-more__control\").text)\n",
        "  pd.DataFrame(output,columns = [\"review\"]).to_csv(\"User_reviews\")\n",
        "#create data frame for all the reviews for data cleaning\n",
        "result_df= pd.DataFrame(output,columns = [\"User_Review\"])\n",
        "#result_df"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMrC93vIsnDP"
      },
      "source": [
        "#Data Cleaning steps:\n",
        "#1.Remove noise, such as special characters and punctuations.\n",
        "#2.Remove numbers\n",
        "#3.Remove stopwords by using the stopwords list\n",
        "#4.Lowercase all texts\n",
        "#5.Stemming\n",
        "#6.Lemmatization.\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize \n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import re\n",
        "stemmer=PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "stop_words=stopwords.words(\"english\")\n",
        "review_filter_stemming=[]\n",
        "review_filter_Lemmatization=[]\n",
        "final_stemmed_review=[]\n",
        "final_lemmatized_review=[]\n",
        "# cleaning the text data\n",
        "result_df['User_Review'] = result_df['User_Review'].str.replace(r\"\\W\", \" \").str.strip()# 1.To remove special characters and punctuations\n",
        "result_df['User_Review']= result_df['User_Review'].str.replace(r'\\d+',\"\") #2.To remove Numbers\n",
        "for a in result_df['User_Review']:\n",
        "    splitting_words=word_tokenize(a)\n",
        "    for b in splitting_words:\n",
        "        if b not in stop_words: #3.Removing Stop Words\n",
        "            b=b.lower() # 4.Coverting text to lower case \n",
        "            stemming=stemmer.stem(b) # 5.perfroming stemming\n",
        "            review_filter_stemming.append(stemming)\n",
        "            lemmatization_words=lemmatizer.lemmatize(b.lower()) # 6.Lemmatization\n",
        "            review_filter_Lemmatization.append(lemmatization_words)\n",
        "    final_stemmed_review.append(' '.join(review_filter_stemming))\n",
        "    final_lemmatized_review.append(' '.join(review_filter_Lemmatization))\n",
        "    review_filter_stemming.clear()\n",
        "    review_filter_Lemmatization.clear()\n",
        "result_df['Review after Stemming']=pd.DataFrame(final_stemmed_review)\n",
        "result_df['Review after Lemmatization']=pd.DataFrame(final_lemmatized_review)\n",
        "result_df['word_count'] = result_df[\"Review after Lemmatization\"].apply(lambda x : len(x.split(\" \")))\n",
        "#result_df\n"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zM10lBPsnZM"
      },
      "source": [
        "# function definition to compute the tf idf and tf-idf values for the starting word in the text\n",
        "\n",
        "#computeTF\n",
        "def computeTF(sentence):\n",
        "  words = sentence.split(\" \")\n",
        "  value = len(set(words))\n",
        "  return words.count(words[0])/value\n",
        "  pass\n",
        "\n",
        "#compute IDF\n",
        "import math \n",
        "def computeIDF(sentence):\n",
        "  words = sentence.lower().split(\" \")\n",
        "  res = words.count(words[0])\n",
        "  return math.log(len(words)/res, 10)\n",
        "  pass"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3TFXlD6seaR"
      },
      "source": [
        "result_df[\"tf\"] = result_df[\"Review after Lemmatization\"].apply(lambda x : round(computeTF(x),4))\n",
        "result_df[\"idf\"] = result_df[\"Review after Lemmatization\"].apply(lambda x : round(computeIDF(x),4))\n",
        "result_df[\"tf-idf\"] = result_df[\"tf\"]*result_df[\"idf\"]\n",
        "#result_df"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb0wMlj7seGc"
      },
      "source": [
        "# syntax and structure analysis\n",
        "#3.1 Parts of Speech (POS) Tagging: \n",
        "import nltk\n",
        "from collections import Counter\n",
        "#initialising\n",
        "tags=[]\n",
        "count_tag=[]\n",
        "count=0\n",
        "# POS tagging\n",
        "for val in result_df['Review after Lemmatization']:\n",
        "    word_tokens=word_tokenize(val)\n",
        "    POS_tags=nltk.pos_tag(word_tokens)\n",
        "    tags.append(POS_tags)\n",
        "from collections import Counter\n",
        "def get_pos(value,tags):\n",
        "  pos_counts=[]\n",
        "  for j in tags:\n",
        "    counts = Counter(tag for word,tag in j)   \n",
        "    pos_counts.append(counts.get(value))\n",
        "  return pos_counts\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WS1hr65tC_PP"
      },
      "source": [
        "import numpy as np\n",
        "result_df[\"Number of nouns\"] = pd.DataFrame(get_pos(\"NN\",tags))\n",
        "result_df[\"Number of verbs\"] = pd.DataFrame(get_pos(\"VB\",tags))\n",
        "result_df[\"Number of predeterminers\"] = pd.DataFrame(get_pos(\"PDT\",tags))\n",
        "result_df[\"Number of adverbs\"] = pd.DataFrame(get_pos(\"RB\",tags))\n",
        "result_df[\"Number of cardinal digits\"] = pd.DataFrame(get_pos(\"CD\", tags))\n",
        "result_df[\"Number of prepositions\"] = pd.DataFrame(get_pos(\"IN\",tags))\n",
        "result_df[\"Number of Determiners\"] = pd.DataFrame(get_pos(\"DT\",tags)) \n",
        "result_df[\"Number of adjectives\"] = pd.DataFrame(get_pos(\"JJ\",tags)) \n",
        "result_df[\"Number of conjunctions\"] = pd.DataFrame(get_pos(\"CC\",tags))\n",
        "result_df[\"Number of pronouns\"] = pd.DataFrame(get_pos(\"PP\",tags))\n",
        "result_df[\"Number of Punctuations\"] = pd.DataFrame(get_pos(\":\",tags))\n",
        "result_df = result_df.fillna(0)\n",
        "pronouns = pd.DataFrame(get_pos(\"PP\",tags))\n",
        "prepositions = pd.DataFrame(get_pos(\"IN\",tags))\n",
        "punctuations = pd.DataFrame(get_pos(\":\",tags))\n",
        "conjunctions = pd.DataFrame(get_pos(\"CC\",tags))\n",
        "result_df[\"Density of pronouns\"] = result_df[\"Number of pronouns\"]/pronouns[0]\n",
        "result_df[\"Density of prepositions\"] = result_df[\"Number of prepositions\"]/prepositions[0]\n",
        "result_df[\"Density of punctuations\"] = result_df[\"Number of Punctuations\"]/punctuations[0]\n",
        "result_df[\"Density of conjunctions\"] = result_df[\"Number of conjunctions\"]/conjunctions[0]\n",
        "#result_df\n",
        "\n"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxkNK9dQDbzS",
        "outputId": "ad585fa8-b099-4684-a7c8-e8f0652fd041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        }
      },
      "source": [
        "final_df = result_df[['User_Review','word_count','tf','idf','tf-idf','Number of nouns','Number of adverb','Number of cardinal digits','Number of Verbs','Number of Determiners','Number of adjectives','Number of interjenctions',\"Density of pronouns\",\"Density of prepositions\",\"Density of punctuations\",\"Density of conjunctions\"]]\n",
        "final_df"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User_Review</th>\n",
              "      <th>word_count</th>\n",
              "      <th>tf</th>\n",
              "      <th>idf</th>\n",
              "      <th>tf-idf</th>\n",
              "      <th>Number of nouns</th>\n",
              "      <th>Number of adverb</th>\n",
              "      <th>Number of cardinal digits</th>\n",
              "      <th>Number of Verbs</th>\n",
              "      <th>Number of Determiners</th>\n",
              "      <th>Number of adjectives</th>\n",
              "      <th>Number of interjenctions</th>\n",
              "      <th>Density of pronouns</th>\n",
              "      <th>Density of prepositions</th>\n",
              "      <th>Density of punctuations</th>\n",
              "      <th>Density of conjunctions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Every once in a while a movie comes  that trul...</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0208</td>\n",
              "      <td>1.6990</td>\n",
              "      <td>0.035339</td>\n",
              "      <td>24.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "      <td>43</td>\n",
              "      <td>0.0270</td>\n",
              "      <td>1.6335</td>\n",
              "      <td>0.044104</td>\n",
              "      <td>15.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Truly a masterpiece  The Best Hollywood film o...</td>\n",
              "      <td>86</td>\n",
              "      <td>0.0299</td>\n",
              "      <td>1.6335</td>\n",
              "      <td>0.048842</td>\n",
              "      <td>29.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Joaquin Phoenix gives a tour de force performa...</td>\n",
              "      <td>54</td>\n",
              "      <td>0.0222</td>\n",
              "      <td>1.7324</td>\n",
              "      <td>0.038459</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "      <td>52</td>\n",
              "      <td>0.0213</td>\n",
              "      <td>1.7160</td>\n",
              "      <td>0.036551</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>A mentally ill person without talents  or inte...</td>\n",
              "      <td>35</td>\n",
              "      <td>0.0741</td>\n",
              "      <td>1.2430</td>\n",
              "      <td>0.092106</td>\n",
              "      <td>17.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>What a legendary character and what a legendar...</td>\n",
              "      <td>27</td>\n",
              "      <td>0.0417</td>\n",
              "      <td>1.4314</td>\n",
              "      <td>0.059689</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Only   audience who think what they do is alwa...</td>\n",
              "      <td>25</td>\n",
              "      <td>0.0417</td>\n",
              "      <td>1.3979</td>\n",
              "      <td>0.058292</td>\n",
              "      <td>12.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>While I enjoyed the film  it felt pretty short...</td>\n",
              "      <td>75</td>\n",
              "      <td>0.0154</td>\n",
              "      <td>1.8751</td>\n",
              "      <td>0.028877</td>\n",
              "      <td>32.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Disturbing  Just got out of the movie  My humo...</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0455</td>\n",
              "      <td>1.3617</td>\n",
              "      <td>0.061957</td>\n",
              "      <td>9.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          User_Review  ...  Density of conjunctions\n",
              "0   Every once in a while a movie comes  that trul...  ...                      NaN\n",
              "1   This is a movie that only those who have felt ...  ...                      1.0\n",
              "2   Truly a masterpiece  The Best Hollywood film o...  ...                      1.0\n",
              "3   Joaquin Phoenix gives a tour de force performa...  ...                      NaN\n",
              "4   Most of the time movies are anticipated like t...  ...                      NaN\n",
              "..                                                ...  ...                      ...\n",
              "95  A mentally ill person without talents  or inte...  ...                      NaN\n",
              "96  What a legendary character and what a legendar...  ...                      NaN\n",
              "97  Only   audience who think what they do is alwa...  ...                      1.0\n",
              "98  While I enjoyed the film  it felt pretty short...  ...                      1.0\n",
              "99  Disturbing  Just got out of the movie  My humo...  ...                      NaN\n",
              "\n",
              "[100 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW9H3fmPG0_A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}