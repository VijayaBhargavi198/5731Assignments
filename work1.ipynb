{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "work1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayaBhargavi198/5731Assignments/blob/master/work1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meyfcj2fe6qQ"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 10/29/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aErIOODme6qR"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SwY_9eZe6qS"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpJxQDKne6qS",
        "outputId": "c2f9d7e7-fb78-4a31-f2f0-616096e668f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install polyglot \n",
        "!pip install pyicu\n",
        "!pip install pycld2\n",
        "!pip install Morfessor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting polyglot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/98/e24e2489114c5112b083714277204d92d372f5bbe00d5507acf40370edb9/polyglot-16.7.4.tar.gz (126kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: polyglot\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52559 sha256=026715fff477850c35fe97721d1b16337f0affa57e546df5df4c766c4a0a2755\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/91/ef/f1369fdc1203b0a9347d4b24f149b83a305f39ab047986d9da\n",
            "Successfully built polyglot\n",
            "Installing collected packages: polyglot\n",
            "Successfully installed polyglot-16.7.4\n",
            "Collecting pyicu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/99/c48c816095208bf3f4936ff67e571621fbddef461303a35a076f234e31f6/PyICU-2.5.tar.gz (225kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyicu\n",
            "  Building wheel for pyicu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyicu: filename=PyICU-2.5-cp36-cp36m-linux_x86_64.whl size=1252574 sha256=613bb69e4dd096a3ff60450f4f0816c7c40e9d29e6404676232224055be8d062\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/3a/28/09f90c38785945ddf9af61b7add1aa62a740f40e259626ef3a\n",
            "Successfully built pyicu\n",
            "Installing collected packages: pyicu\n",
            "Successfully installed pyicu-2.5\n",
            "Collecting pycld2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/d2/8b0def84a53c88d0eb27c67b05269fbd16ad68df8c78849e7b5d65e6aec3/pycld2-0.41.tar.gz (41.4MB)\n",
            "\u001b[K     |████████████████████████████████| 41.4MB 107kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp36-cp36m-linux_x86_64.whl size=9833517 sha256=9b8a4c87a4e502abdc7101bdf6b64c1ddae7345aa61f07427107fdfa84baab60\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/8f/e9/08a1a8932a490175bd140206cd86a3dbcfc70498100de11079\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n",
            "Collecting Morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Installing collected packages: Morfessor\n",
            "Successfully installed Morfessor-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaUbbAJsfVr-",
        "outputId": "e124ea2a-576f-4819-98b0-8bfe3cbcfc40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%bash\n",
        "polyglot download embeddings2.en pos2.en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[polyglot_data] Downloading package embeddings2.en to\n",
            "[polyglot_data]     /root/polyglot_data...\n",
            "[polyglot_data] Downloading package pos2.en to /root/polyglot_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W6VXzi7fcMV",
        "outputId": "42f6dabe-1060-4904-f8f9-1a90b94e4e0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from polyglot.text import Text\n",
        "df=pd.read_csv(\"/content/sample_data/Joker_user_reviews.csv\")\n",
        "blob = df[\"review\"].to_string()\n",
        "text = Text(blob)\n",
        "tags=text.pos_tags\n",
        "#tags\n",
        "sent_word = [x for (x,y) in tags if y not in ('NUM','PUNCT','ADP','AUX','CONJ','DET','INTJ','NOUN','PART','PRON','PROPN','SCONJ','SYM','X')]\n",
        "sent_word"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['once',\n",
              " 'comes',\n",
              " 'is',\n",
              " 'only',\n",
              " 'felt',\n",
              " 'Truly',\n",
              " 'Best',\n",
              " 'gives',\n",
              " 'de',\n",
              " 'anticipated',\n",
              " 'Let',\n",
              " 'start',\n",
              " 'off',\n",
              " 'get',\n",
              " 'why',\n",
              " 'hate',\n",
              " 'seen',\n",
              " 'yesterday',\n",
              " 'early',\n",
              " 'sad',\n",
              " 'missed',\n",
              " 'causes',\n",
              " 'consider',\n",
              " 'acting',\n",
              " 'affects',\n",
              " 'makes',\n",
              " 'p',\n",
              " 'say',\n",
              " 'more',\n",
              " 'stop',\n",
              " 'watching',\n",
              " 'quit',\n",
              " 'relying',\n",
              " 'ago',\n",
              " 'thought',\n",
              " 'was',\n",
              " 'good',\n",
              " 'just',\n",
              " \"don't\",\n",
              " 'went',\n",
              " 'expecting',\n",
              " 'really',\n",
              " 'understand',\n",
              " 'here',\n",
              " 'When',\n",
              " 'heard',\n",
              " 'saying',\n",
              " 'is',\n",
              " 'gives',\n",
              " 'recurring',\n",
              " 'so',\n",
              " 'many',\n",
              " 'intense',\n",
              " 'write',\n",
              " 'just',\n",
              " 'say',\n",
              " 'more',\n",
              " 'was',\n",
              " 'so',\n",
              " 'hyped',\n",
              " 'see',\n",
              " 'loved',\n",
              " 'BREAKING',\n",
              " 'are',\n",
              " 'back',\n",
              " 'perfect',\n",
              " 'convinces',\n",
              " 'always',\n",
              " 'meant',\n",
              " 'need',\n",
              " 'need',\n",
              " 'Amazing',\n",
              " 'thought',\n",
              " 'was',\n",
              " 'complete',\n",
              " 'utter',\n",
              " 'expecting',\n",
              " 'worthy',\n",
              " 'sociopathic',\n",
              " 'mentally',\n",
              " 'best',\n",
              " 'few',\n",
              " 'unbelievable',\n",
              " 'Dare',\n",
              " 'say',\n",
              " 'better',\n",
              " 'answers',\n",
              " 't',\n",
              " 'see',\n",
              " 'is',\n",
              " \"don't\",\n",
              " 'understand',\n",
              " 'high',\n",
              " 'went',\n",
              " 'incredible',\n",
              " 'was',\n",
              " 'was',\n",
              " 'almost',\n",
              " 'unconvincing',\n",
              " 'laughing',\n",
              " 'best',\n",
              " 'is',\n",
              " 'mental',\n",
              " 'keeping',\n",
              " 'short',\n",
              " 'is',\n",
              " 'literally',\n",
              " 'cinematic',\n",
              " 'here',\n",
              " 'making',\n",
              " 'never',\n",
              " 'left',\n",
              " 'good',\n",
              " 'is',\n",
              " 'absolutely',\n",
              " 'making',\n",
              " 'sure',\n",
              " 'give',\n",
              " 'Creative',\n",
              " 'embodied',\n",
              " 'give',\n",
              " 'compelling',\n",
              " 'new',\n",
              " 'Absolute',\n",
              " 'believed',\n",
              " 'silly',\n",
              " 'masquerading',\n",
              " 'beautify',\n",
              " 'was',\n",
              " 'was',\n",
              " 'Best',\n",
              " 'seen',\n",
              " 'does',\n",
              " 'first',\n",
              " 'Amazing',\n",
              " 'Highly',\n",
              " 'enjoyable',\n",
              " 'Dark',\n",
              " 'very',\n",
              " 'entertaining',\n",
              " 'Hoping',\n",
              " 'is',\n",
              " 'likes',\n",
              " 'dark',\n",
              " 'plays',\n",
              " 'found',\n",
              " 'perfect',\n",
              " 'acting',\n",
              " 'best',\n",
              " 'ever',\n",
              " 'dark',\n",
              " 'be',\n",
              " 'was',\n",
              " 'think',\n",
              " 'understandable',\n",
              " 'see',\n",
              " 'why',\n",
              " 'says',\n",
              " 'messed',\n",
              " 'interesting',\n",
              " 'real',\n",
              " 'here',\n",
              " 'are',\n",
              " 'rating',\n",
              " 'say',\n",
              " 'how',\n",
              " 'brilliant',\n",
              " 'is',\n",
              " 'understand',\n",
              " 'why',\n",
              " 'find',\n",
              " 'so',\n",
              " 'hyped',\n",
              " 'p',\n",
              " 'agree',\n",
              " 'was',\n",
              " 'is',\n",
              " 'unique',\n",
              " 'is',\n",
              " 'more',\n",
              " 'outstanding',\n",
              " 'is',\n",
              " 'so',\n",
              " 'strong',\n",
              " 'so',\n",
              " 'is',\n",
              " 'stunning',\n",
              " 'is',\n",
              " 'basically',\n",
              " 'lite',\n",
              " 'so',\n",
              " 'looking',\n",
              " 'forward',\n",
              " 'given',\n",
              " 'was',\n",
              " 'excellent',\n",
              " 'amazing',\n",
              " 'plan',\n",
              " 'watching',\n",
              " 'suggest',\n",
              " 'go',\n",
              " 'watch',\n",
              " 'is',\n",
              " 'first',\n",
              " 'was',\n",
              " 'just',\n",
              " 'really',\n",
              " 'unconvincing',\n",
              " 'say',\n",
              " 'is',\n",
              " 'just',\n",
              " 'playing',\n",
              " 'is',\n",
              " 'excellent',\n",
              " 'is',\n",
              " 'good',\n",
              " 'is']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-JYqiD6fcVD",
        "outputId": "e60bce3b-d779-4916-c0dc-b6b5fef7de6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import collections\n",
        "from operator import itemgetter\n",
        "N = 220\n",
        "frequency = collections.Counter(sent_word)\n",
        "top_words = sorted(frequency.items(), key=itemgetter(1), reverse=True)[:N]\n",
        "for i, (word, frequency) in enumerate(top_words, start=1):\n",
        "    print(\"%d %s %d\" % (i, word, frequency))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 is 18\n",
            "2 was 11\n",
            "3 so 6\n",
            "4 say 5\n",
            "5 just 4\n",
            "6 why 3\n",
            "7 more 3\n",
            "8 good 3\n",
            "9 understand 3\n",
            "10 here 3\n",
            "11 see 3\n",
            "12 best 3\n",
            "13 Best 2\n",
            "14 gives 2\n",
            "15 seen 2\n",
            "16 acting 2\n",
            "17 p 2\n",
            "18 watching 2\n",
            "19 thought 2\n",
            "20 don't 2\n",
            "21 went 2\n",
            "22 expecting 2\n",
            "23 really 2\n",
            "24 hyped 2\n",
            "25 are 2\n",
            "26 perfect 2\n",
            "27 need 2\n",
            "28 Amazing 2\n",
            "29 unconvincing 2\n",
            "30 making 2\n",
            "31 give 2\n",
            "32 first 2\n",
            "33 dark 2\n",
            "34 excellent 2\n",
            "35 once 1\n",
            "36 comes 1\n",
            "37 only 1\n",
            "38 felt 1\n",
            "39 Truly 1\n",
            "40 de 1\n",
            "41 anticipated 1\n",
            "42 Let 1\n",
            "43 start 1\n",
            "44 off 1\n",
            "45 get 1\n",
            "46 hate 1\n",
            "47 yesterday 1\n",
            "48 early 1\n",
            "49 sad 1\n",
            "50 missed 1\n",
            "51 causes 1\n",
            "52 consider 1\n",
            "53 affects 1\n",
            "54 makes 1\n",
            "55 stop 1\n",
            "56 quit 1\n",
            "57 relying 1\n",
            "58 ago 1\n",
            "59 When 1\n",
            "60 heard 1\n",
            "61 saying 1\n",
            "62 recurring 1\n",
            "63 many 1\n",
            "64 intense 1\n",
            "65 write 1\n",
            "66 loved 1\n",
            "67 BREAKING 1\n",
            "68 back 1\n",
            "69 convinces 1\n",
            "70 always 1\n",
            "71 meant 1\n",
            "72 complete 1\n",
            "73 utter 1\n",
            "74 worthy 1\n",
            "75 sociopathic 1\n",
            "76 mentally 1\n",
            "77 few 1\n",
            "78 unbelievable 1\n",
            "79 Dare 1\n",
            "80 better 1\n",
            "81 answers 1\n",
            "82 t 1\n",
            "83 high 1\n",
            "84 incredible 1\n",
            "85 almost 1\n",
            "86 laughing 1\n",
            "87 mental 1\n",
            "88 keeping 1\n",
            "89 short 1\n",
            "90 literally 1\n",
            "91 cinematic 1\n",
            "92 never 1\n",
            "93 left 1\n",
            "94 absolutely 1\n",
            "95 sure 1\n",
            "96 Creative 1\n",
            "97 embodied 1\n",
            "98 compelling 1\n",
            "99 new 1\n",
            "100 Absolute 1\n",
            "101 believed 1\n",
            "102 silly 1\n",
            "103 masquerading 1\n",
            "104 beautify 1\n",
            "105 does 1\n",
            "106 Highly 1\n",
            "107 enjoyable 1\n",
            "108 Dark 1\n",
            "109 very 1\n",
            "110 entertaining 1\n",
            "111 Hoping 1\n",
            "112 likes 1\n",
            "113 plays 1\n",
            "114 found 1\n",
            "115 ever 1\n",
            "116 be 1\n",
            "117 think 1\n",
            "118 understandable 1\n",
            "119 says 1\n",
            "120 messed 1\n",
            "121 interesting 1\n",
            "122 real 1\n",
            "123 rating 1\n",
            "124 how 1\n",
            "125 brilliant 1\n",
            "126 find 1\n",
            "127 agree 1\n",
            "128 unique 1\n",
            "129 outstanding 1\n",
            "130 strong 1\n",
            "131 stunning 1\n",
            "132 basically 1\n",
            "133 lite 1\n",
            "134 looking 1\n",
            "135 forward 1\n",
            "136 given 1\n",
            "137 amazing 1\n",
            "138 plan 1\n",
            "139 suggest 1\n",
            "140 go 1\n",
            "141 watch 1\n",
            "142 playing 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOsqKmsEe6qV"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpuftVSWe6qV"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Your analysis here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}