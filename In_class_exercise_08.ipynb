{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "In_class_exercise_08.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayaBhargavi198/5731Assignments/blob/master/In_class_exercise_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meyfcj2fe6qQ"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 10/29/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aErIOODme6qR"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SwY_9eZe6qS"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpJxQDKne6qS"
      },
      "source": [
        "!pip install polyglot \n",
        "!pip install pyicu\n",
        "!pip install pycld2\n",
        "!pip install Morfessor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaUbbAJsfVr-"
      },
      "source": [
        "%%bash\n",
        "polyglot download embeddings2.en pos2.en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W6VXzi7fcMV",
        "outputId": "cca8f903-d2cd-46bd-f8ba-f4c2491abe96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from polyglot.text import Text\n",
        "df=pd.read_csv(\"/content/sample_data/Joker_user_reviews.csv\")\n",
        "preprocessed_data=[]\n",
        "df[\"review\"] = df[\"review\"].str.replace(r\"\\W\", \" \").str.strip()# 1.To remove special characters and punctuations\n",
        "df[\"review\"]= df[\"review\"].str.replace(r'\\d+',\"\") #2.To remove Numbers\n",
        "for a in df[\"review\"]:   #3.To chane all the sentences to lower case\n",
        "   a=a.lower()\n",
        "   preprocessed_data.append(a)\n",
        "df['Preprocessed data']=pd.DataFrame(preprocessed_data)\n",
        "blob = df['Preprocessed data'].to_string()\n",
        "text = Text(blob)\n",
        "tags=text.pos_tags\n",
        "#tags\n",
        "sent_word = [x for (x,y) in tags if y not in ('NUM','PUNCT','ADP','AUX','CONJ','DET','INTJ','NOUN','PART','PRON','PROPN','SCONJ','SYM','X','VERB','ADV')] #took only adjectives beacuse they are the prime contributors for sentiment analysis\n",
        "sent_word\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best',\n",
              " 'de',\n",
              " 'most',\n",
              " 'early',\n",
              " 'sad',\n",
              " 'good',\n",
              " 'recurring',\n",
              " 'many',\n",
              " 'intense',\n",
              " 'more',\n",
              " 'perfect',\n",
              " 'amazing',\n",
              " 'brilliant',\n",
              " 'magnificent',\n",
              " 'complete',\n",
              " 'worthy',\n",
              " 'best',\n",
              " 'few',\n",
              " 'unbelievable',\n",
              " 'high',\n",
              " 'incredible',\n",
              " 'unconvincing',\n",
              " 'best',\n",
              " 'mental',\n",
              " 'short',\n",
              " 'cinematic',\n",
              " 'good',\n",
              " 'sure',\n",
              " 'creative',\n",
              " 'compelling',\n",
              " 'new',\n",
              " 'absolute',\n",
              " 'silly',\n",
              " 'best',\n",
              " 'my',\n",
              " 'first',\n",
              " 'amazing',\n",
              " 'enjoyable',\n",
              " 'dark',\n",
              " 'entertaining',\n",
              " 'dark',\n",
              " 'perfect',\n",
              " 'best',\n",
              " 'dark',\n",
              " 'understandable',\n",
              " 'interesting',\n",
              " 'real',\n",
              " 'brilliant',\n",
              " 'hyped',\n",
              " 'unique',\n",
              " 'more',\n",
              " 'outstanding',\n",
              " 'strong',\n",
              " 'mr',\n",
              " 'stunning',\n",
              " 'lite',\n",
              " 'excellent',\n",
              " 'amazing',\n",
              " 'first',\n",
              " 'unconvincing',\n",
              " 'excellent',\n",
              " 'good']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-JYqiD6fcVD",
        "outputId": "11706bc5-ad34-4d95-d006-726402a47f9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import collections\n",
        "from operator import itemgetter\n",
        "N = 200\n",
        "frequency = collections.Counter(sent_word)\n",
        "top_words = sorted(frequency.items(), key=itemgetter(1), reverse=True)[:N]\n",
        "for i, (word, frequency) in enumerate(top_words, start=1):\n",
        "    print(\"%d %s %d\" % (i, word, frequency))\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 best 5\n",
            "2 good 3\n",
            "3 amazing 3\n",
            "4 dark 3\n",
            "5 more 2\n",
            "6 perfect 2\n",
            "7 brilliant 2\n",
            "8 unconvincing 2\n",
            "9 first 2\n",
            "10 excellent 2\n",
            "11 de 1\n",
            "12 most 1\n",
            "13 early 1\n",
            "14 sad 1\n",
            "15 recurring 1\n",
            "16 many 1\n",
            "17 intense 1\n",
            "18 magnificent 1\n",
            "19 complete 1\n",
            "20 worthy 1\n",
            "21 few 1\n",
            "22 unbelievable 1\n",
            "23 high 1\n",
            "24 incredible 1\n",
            "25 mental 1\n",
            "26 short 1\n",
            "27 cinematic 1\n",
            "28 sure 1\n",
            "29 creative 1\n",
            "30 compelling 1\n",
            "31 new 1\n",
            "32 absolute 1\n",
            "33 silly 1\n",
            "34 my 1\n",
            "35 enjoyable 1\n",
            "36 entertaining 1\n",
            "37 understandable 1\n",
            "38 interesting 1\n",
            "39 real 1\n",
            "40 hyped 1\n",
            "41 unique 1\n",
            "42 outstanding 1\n",
            "43 strong 1\n",
            "44 mr 1\n",
            "45 stunning 1\n",
            "46 lite 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOsqKmsEe6qV"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpuftVSWe6qV",
        "outputId": "7c087421-83fc-497b-9caf-3b6636c642b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Sentiment Analysis using TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('movie_reviews')\n",
        "from textblob import TextBlob\n",
        "from textblob.sentiments import NaiveBayesAnalyzer\n",
        "preprocessed_data=[]\n",
        "df[\"review\"] = df[\"review\"].str.replace(r\"\\W\", \" \").str.strip()# 1.To remove special characters and punctuations\n",
        "df[\"review\"]= df[\"review\"].str.replace(r'\\d+',\"\") #2.To remove Numbers\n",
        "for a in df[\"review\"]:   #3.To chane all the sentences to lower case\n",
        "   a=a.lower()\n",
        "   preprocessed_data.append(a)\n",
        "df['Preprocessed data']=pd.DataFrame(preprocessed_data)\n",
        "text= df['Preprocessed data'].to_string()\n",
        "blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
        "NaiveBayes_SentimentScore=blob.sentiment.classification\n",
        "NaiveBayes_SentimentScore"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'pos'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FdCY4slNQtV"
      },
      "source": [
        "# Sentiment Analysis using VADER "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nJrfk81NQdD"
      },
      "source": [
        "# Sentiment Analysis using TFIDF-based Support Vector Machine (SVM)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}