{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "In_class_exercise_08.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNqBmIlVpMMe2ilBKK1CZJP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VijayaBhargavi198/5731Assignments/blob/master/In_class_exercise_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxL4LBbfw3Ho"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P8iW2TgEKHc",
        "outputId": "2b6976eb-b6bf-496d-f390-e10ed14de78d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop = stopwords.words('english')\n",
        "from nltk.tokenize import word_tokenize \n",
        "import re\n",
        "from textblob import TextBlob\n",
        "\n",
        "input_df=pd.read_csv(\"/content/sample_data/Joker_user_reviews.csv\")\n",
        "\n",
        "# cleaning the text data\n",
        "stop_words=stopwords.words(\"english\")\n",
        "input_df['review'] = input_df['review'].str.replace(r\"\\W\", \" \").str.strip()# 1.To remove special characters and punctuations\n",
        "input_df['review']= input_df['review'].str.replace(r'\\d+',\"\") #2.To remove Numbers\n",
        "input_df['cleaned text review'] = input_df['review'].apply(lambda x: \" \".join(x.lower() for x in x.split())) #convert the whole text into lower case\n",
        "input_df['cleaned text review'] = input_df['review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop)) #remove all stop words\n",
        "input_df['cleaned text review'] = input_df['review'].apply(lambda x: nltk.word_tokenize(x)) #tokenise the cleaned data\n",
        "# input_df['cleaned text review'] # dataframe column that would be used for further process\n",
        "#find the word count of all the words from cleaned text reviews\n",
        "word_count_df = (input_df['cleaned text review']).apply(lambda x: pd.value_counts(x)).sum(axis = 0).reset_index() # counting the term frequency/ word_count\n",
        "word_count_df.columns = ['sentiment_words', 'word_count']\n",
        "#find polarity of all the words \n",
        "word_polarity=[]\n",
        "for i in word_count_df['sentiment_words']:\n",
        "  p=TextBlob(i).sentiment.polarity\n",
        "  word_polarity.append(p)\n",
        "word_count_df['polarity']= pd.DataFrame(word_polarity)\n",
        "# sentiment related words are the words that hold positive or negative value in the sentence, hence words with polarity zero are not needed\n",
        "sentiment_related_terms = word_count_df.loc[word_count_df['polarity'] != 0]\n",
        "#ranking them according to the word count\n",
        "sentiment_related_terms.sort_values(by='word_count', ascending=False).reset_index()# index reset in itself gives the rank"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>sentiment_words</th>\n",
              "      <th>word_count</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>356</td>\n",
              "      <td>good</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>235</td>\n",
              "      <td>more</td>\n",
              "      <td>38.0</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>272</td>\n",
              "      <td>very</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>218</td>\n",
              "      <td>many</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>43</td>\n",
              "      <td>best</td>\n",
              "      <td>23.0</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>1111</td>\n",
              "      <td>psychotic</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>1113</td>\n",
              "      <td>BEST</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>1124</td>\n",
              "      <td>frustrated</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>1136</td>\n",
              "      <td>Original</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>2239</td>\n",
              "      <td>confusing</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>376 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     index sentiment_words  word_count  polarity\n",
              "0      356            good        45.0     0.700\n",
              "1      235            more        38.0     0.500\n",
              "2      272            very        32.0     0.200\n",
              "3      218            many        26.0     0.500\n",
              "4       43            best        23.0     1.000\n",
              "..     ...             ...         ...       ...\n",
              "371   1111       psychotic         1.0    -0.500\n",
              "372   1113            BEST         1.0     1.000\n",
              "373   1124      frustrated         1.0    -0.700\n",
              "374   1136        Original         1.0     0.375\n",
              "375   2239       confusing         1.0    -0.300\n",
              "\n",
              "[376 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 454
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvb76j0qw-PK"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVXxKuf1F8Z4",
        "outputId": "73afd4b4-d4bc-4454-9216-1d1609884d12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize  \n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop_words=stopwords.words(\"english\")\n",
        "clean_text_review=[]\n",
        "clean_text=[]\n",
        "input_df=pd.read_csv(\"/content/sample_data/Joker_user_reviews.csv\")\n",
        "# cleaning the text data\n",
        "input_df['review'] = input_df['review'].str.replace(r\"\\W\", \" \").str.strip()# 1.To remove special characters and punctuations\n",
        "input_df['review']= input_df['review'].str.replace(r'\\d+',\"\") #2.To remove Numbers\n",
        "for a in input_df['review']:\n",
        "    splitting_words=word_tokenize(str(a))\n",
        "    for b in splitting_words:\n",
        "        if b not in stop_words: #3.Removing Stop Words\n",
        "            b=b.lower() # 4.Coverting text to lower case \n",
        "            clean_text.append(b)\n",
        "    clean_text_review.append(' '.join(clean_text))\n",
        "    clean_text.clear()\n",
        "input_df['cleaned text review']=pd.DataFrame(clean_text_review) #column that we would be using for further analysis\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSJTryTyOfcg",
        "outputId": "1eff374c-0f1e-413f-ea2e-351b62a886c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#TEXTBLOB\n",
        "input_df = input_df.dropna() #there might still be some NAN values, removing those \n",
        "input_df['polarity'] = input_df['cleaned text review'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "def text_sentiment(x):\n",
        "  if(x > 0):\n",
        "    return \"positive\"\n",
        "  if(x < 0):\n",
        "    return \"negative\"\n",
        "  if(x == 0):\n",
        "    return \"neutral\"\n",
        "input_df['output sentiment'] = input_df['polarity'].apply(lambda x: text_sentiment(x))\n",
        "input_df\n",
        "print(input_df[['cleaned text review', 'polarity', 'Sentiment','output sentiment']].head(5))\n",
        "\n",
        "#find accuracy\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "# we have the formula sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)\n",
        "accuracy = accuracy_score(input_df['Sentiment'], input_df['output sentiment'])\n",
        "textblob_accuracy = accuracy *100\n",
        "print('The accuracy of the TextBlob sentiment analysis is:', textblob_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                 cleaned text review  ...  output sentiment\n",
            "0  every movie comes truly makes impact joaquin p...  ...          positive\n",
            "1  this movie felt alone isolated truly relate yo...  ...           neutral\n",
            "2  truly masterpiece the best hollywood film one ...  ...          positive\n",
            "3  joaquin phoenix gives tour de force performanc...  ...          positive\n",
            "4  most time movies anticipated like end falling ...  ...          positive\n",
            "\n",
            "[5 rows x 4 columns]\n",
            "The accuracy of the TextBlob sentiment analysis is: 68.23529411764706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqK82l0frUrG",
        "outputId": "787bd6ae-ca75-4cb1-a68b-9ba7f727e54b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# VADER\n",
        "input_df = input_df.dropna()#there might still be some NAN values, removing those\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "vader = SentimentIntensityAnalyzer()\n",
        "input_df['polarity'] = input_df['cleaned text review'].apply(lambda x:vader.polarity_scores(x)['compound'])\n",
        "def text_sentiment(x):\n",
        "  if(x > 0):\n",
        "    return \"positive\"\n",
        "  if(x < 0):\n",
        "    return \"negative\"\n",
        "  if(x == 0):\n",
        "    return \"neutral\"\n",
        "input_df['output sentiment'] = input_df['polarity'].apply(lambda x: text_sentiment(x))\n",
        "input_df\n",
        "print(input_df[['cleaned text review', 'polarity', 'Sentiment','output sentiment']].head(5))\n",
        "\n",
        "#find accuracy\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "# we have the formula sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)\n",
        "accuracy = accuracy_score(input_df['Sentiment'], input_df['output sentiment'])\n",
        "Vader_accuracy = accuracy *100\n",
        "print( 'The accuracy of the Vedar sentiment analysis is:', Vader_accuracy)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "                                 cleaned text review  polarity output sentiment\n",
            "0  every movie comes truly makes impact joaquin p...    0.9531         positive\n",
            "1  this movie felt alone isolated truly relate yo...    0.9648         positive\n",
            "2  truly masterpiece the best hollywood film one ...    0.9732         positive\n",
            "3  joaquin phoenix gives tour de force performanc...    0.8316         positive\n",
            "4  most time movies anticipated like end falling ...   -0.5719         negative\n",
            "The accuracy of the Vedar sentiment analysis is: 63.52941176470588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUHywV0BDVMF",
        "outputId": "2d3c02d7-9874-4d46-f6cb-a44a34949ce0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#SVM\n",
        "input_df = input_df.dropna()#there might still be some NAN values, removing those\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = sklearn.model_selection.train_test_split(input_df, train_size=0.6, test_size=0.4) #splitting data into test and train\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "#defining the pipeline\n",
        "pipeline = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),('clf', SGDClassifier(max_iter=100, learning_rate='optimal'))])\n",
        "svm_result = pipeline.fit(train['cleaned text review'], train['Sentiment'])\n",
        "test['output sentiment'] = svm_result.predict(test['cleaned text review'])\n",
        "print(test[['Sentiment','output sentiment']].head(10))\n",
        "\n",
        "#find accuracy\n",
        "# we have the formula sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)\n",
        "accuracy = accuracy_score(test['Sentiment'], test['output sentiment'])\n",
        "svm_accuracy = accuracy *100\n",
        "print('\\n', 'The accuracy of the TFIDF-based SVM sentiment model is:', svm_accuracy)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Sentiment output sentiment\n",
            "69  negative         positive\n",
            "37  negative         positive\n",
            "21  positive         positive\n",
            "59  positive         positive\n",
            "46  positive         positive\n",
            "32  positive         positive\n",
            "2   positive         positive\n",
            "45  negative         negative\n",
            "39  negative         negative\n",
            "10  positive         positive\n",
            "\n",
            " The accuracy of the TFIDF-based SVM sentiment identification is: 76.47058823529412\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp3up7zEgna-"
      },
      "source": [
        "On Running all algorithms, I found the accuracy to be higher in case of SVM compared to textblob and vader, thus i conclude, for my dataset and my modelling svm turned out to be more accurate.\n",
        "Accuracy of all three models are as follows\n",
        "Textblob =68.2 \n",
        "Vader = 63.5 \n",
        "SVM = 76.47 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y9iDOctEZXf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}